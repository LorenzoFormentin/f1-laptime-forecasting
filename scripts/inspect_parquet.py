from __future__ import annotations

import argparse
from pathlib import Path

import pandas as pd


def _print_df_info(df: pd.DataFrame, name: str, max_cols: int = 40) -> None:
    print("\n" + "=" * 80)
    print(f"{name}")
    print("=" * 80)

    print(f"Shape: {df.shape}")
    print("\nDtypes:")
    # print dtypes in a stable order
    dtypes = df.dtypes.astype(str)
    if len(dtypes) > max_cols:
        print(dtypes.head(max_cols).to_string())
        print(f"... ({len(dtypes) - max_cols} more columns)")
    else:
        print(dtypes.to_string())

    print("\nHead (10):")
    with pd.option_context("display.max_columns", 200, "display.width", 160):
        print(df.head(10))

    # Useful quick checks if present
    if "LapTime_s" in df.columns:
        print("\nLapTime_s summary:")
        print(df["LapTime_s"].describe())

    if "LapTime_next_s" in df.columns:
        print("\nLapTime_next_s summary:")
        print(df["LapTime_next_s"].describe())


def main() -> None:
    p = argparse.ArgumentParser(description="Inspect parquet datasets generated by the pipeline")
    p.add_argument(
        "--path",
        type=str,
        default="",
        help="Path to a parquet file. If omitted, the script will inspect the latest files in data/interim and data/processed.",
    )
    p.add_argument("--data-dir", type=str, default="data", help="Project data directory (default: data)")
    args = p.parse_args()

    data_dir = Path(args.data_dir)

    if args.path:
        path = Path(args.path)
        if not path.exists():
            raise SystemExit(f"File not found: {path}")
        df = pd.read_parquet(path)
        _print_df_info(df, name=str(path))
        return

    # Otherwise: find the latest in interim and processed
    interim = sorted((data_dir / "interim").glob("*.parquet"), key=lambda p: p.stat().st_mtime)
    processed = sorted((data_dir / "processed").glob("*.parquet"), key=lambda p: p.stat().st_mtime)

    if interim:
        latest_interim = interim[-1]
        df_i = pd.read_parquet(latest_interim)
        _print_df_info(df_i, name=f"Latest interim: {latest_interim}")
    else:
        print("No interim parquet files found in data/interim/")

    if processed:
        latest_processed = processed[-1]
        df_p = pd.read_parquet(latest_processed)
        _print_df_info(df_p, name=f"Latest processed: {latest_processed}")
    else:
        print("No processed parquet files found in data/processed/")


if __name__ == "__main__":
    main()
